# PRODIGY_ML_04

# âœ‹ Hand Gesture Recognition using CNN

This project implements a **Convolutional Neural Network (CNN)** to recognize hand gestures using webcam input. The model is trained on the **[LeapGestRecog Dataset](https://www.kaggle.com/datasets/gti-upm/leapgestrecog)** and supports real-time gesture prediction using OpenCV and TensorFlow.

---

## ğŸ¯ Objective

To classify static hand gestures in real time from a webcam feed using a CNN trained on grayscale gesture images.

---

## ğŸ§  Model Overview

- **Algorithm**: Convolutional Neural Network (CNN)
- **Framework**: TensorFlow / Keras
- **Evaluation Metric**: Accuracy
- **Tools Used**: Python, OpenCV, NumPy, TensorFlow, Scikit-learn

---

## ğŸ“¦ Features

- ğŸ“· **Webcam Support**: Real-time prediction
- ğŸ” **Preprocessing**: Resize to 128x128, grayscale, normalize
- ğŸ§  **Model**: 3 convolutional layers + dense classifier
- ğŸ—‚ï¸ **10 Gesture Classes**:
  - Palm
  - Fist
  - Thumb
  - Index
  - L
  - OK
  - Palm Moved
  - Fist Moved
  - C
  - Down

---

## ğŸ§ª Training Details

- Dataset: [LeapGestRecog](https://www.kaggle.com/datasets/gti-upm/leapgestrecog)
- Preprocessing:
  - Resize to **128x128**
  - Grayscale + Normalize
  - One-hot encode labels
- CNN Architecture:
  - Conv2D â†’ MaxPool â†’ Dropout
  - Flatten â†’ Dense (ReLU) â†’ Dense (Softmax)
- Trained for: `50 epochs` (adjustable)

---

## ğŸ› ï¸ Dependencies
Install all required packages:
- tensorflow>=2.8.0

- opencv-python

- numpy

- scikit-learn

- joblib

- matplotlib

---

## â–¶ï¸ Running the App

```bash
cd app/
python webcam_app.py
```
---

## ğŸ“Š Results
âœ… Accuracy: ~97% on test set

ğŸ¯ Real-time predictions with consistent outputs in good lighting

ğŸ” Debug output shows prediction vector, decoded label

---

## ğŸ“Œ Notes
- Lighting and hand positioning significantly affect webcam accuracy.

- Consider using background removal or segmentation for better performance.

- Extendable to gesture-based control systems or sign language recognition.

